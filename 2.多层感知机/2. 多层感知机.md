上一个程序尝试了通过调整权重（也就是函数方程的参数）来实现拟合，构建了一个简单的AI模型

但是可以看到测试的时候，他的表现并不是十分完美，其实更多的训练轮数和更加完善的训练数据（随机数导致最后的偏移量可能会偶尔的偏大）或者调整学习率都可以优化结果

而对于本身我们输入数据只进行了一次运算就输出，我们也可以提升到经过多轮计算再输出

<------------>

然后在简单多轮计算的基础上，我们可以考虑到如果是直线的进行计算，即X2=X1*Z1*Z2，那么和我们单层计算X2=X1*(Z1*Z2)其实是一样的（线性变化是可以合并的）

为了更好地让我们的模型可以有更强的特征提取，拟合更加复杂的模式，我们就可以尝试用更加复杂的多层计算，比如不再是简单的进行线性计算

首先我们尝试对于第二层的每一个特征，它都与第一层所有的量相关，也就是说：

比如对于一组数据[X1,X2]，我们希望计算得到[Y11,Y12]，然后进一步计算得到（[Y21,Y22],[Y31,Y32],……）最后计算输出AN

就可以设置Y1=[(X1*Z11a)+(X2*Z11b)+C1（偏移量）]  Y2=[(X1*Z12a)+(X2*Z12b)+C2（偏移量）]

这样以来我们就得到“非简单线性”传递下来的一组新的数据

<------------>

但是仅仅这样还不够，因为如果我们尝试增加更多的层数就会发现：

由于多层线性变换等价于单层线性变换，即使我们设置再多的层数，它实际起作用的也仅仅等价于一层这样的“非简单线性”的变化

因为我们本质是进行了矩阵的运算，举例：Y1=W1*X+b1 和 Y2=W2*Y1+b2 这就是进行了第二次计算得到的Y2

但是我们带入一下就发现Y2=W2*(W1*X+b1)+b2=(W2*W1)·X+(W2*b1+b2) 本质上还是一个线性变化

<------------>

于是我们进一步添加非线性的变化，在计算完tmp=[(X1*Z11a)+(X2*Z11b)+C1（偏移量）]，后将Y1=非线性变化的激活函数(tmp)计算出来

这样以来就实现了非线性的变化

而且由于我们新的一层可以通过设置多个权重+偏移量进行计算，所以实际上我们甚至可以对2元输入计算出10000元的中间层提取值，然后重新计算得到输出层的数据

还可以在中间层进行任意的变换、设置任意的层数，这样一来多层神经网络通过多层非线性变换，可以逼近任意复杂的连续函数。这就是多层感知机的技术。

<------------>

多层感知机（MLP）

输入层：接收外部数据。

原理：输入层中的每个神经元对应一个特征或输入变量。输入层不做任何处理，只是将这些原始数据传递给下一层（隐藏层）。

隐藏层：对输入数据进行复杂的非线性变换，提取数据中的高级特征。

原理：隐藏层由多个神经元组成，每个神经元都与前一层的所有神经元相连，并通过权重和偏置进行加权求和，然后应用激活函数。隐藏层的数量和每一层的神经元数量可以根据任务的复杂度进行调整。隐藏层的存在使得模型能够拟合更复杂的模式。

输出层：生成最终的预测结果。

原理：输出层的神经元根据任务的不同，可以是一个或多个。对于回归任务（如预测数值），通常只有一个神经元；对于分类任务（如识别图片中的物体类别），则可能有多个神经元，每个神经元代表一个类别。输出层同样会对来自最后一层隐藏层的数据进行加权求和并应用激活函数，以生成最终的输出。

根据通用逼近定理，只要网络足够深且有足够的神经元，带有非线性激活函数的前馈神经网络可以以任意精度逼近任何连续函数。

<------------>

而且每个神经元通过加权求和和激活函数，对输入数据进行变换，可以提取出某些特征。

例如，在图像识别任务中，浅层神经元可能学习到边缘和纹理等低级特征（直接输入的数据，通过权重和偏移变化得到）

而深层神经元则可以组合这些低级特征，学习到更复杂的形状和对象（将边缘和纹理组合了起来）

又例如，一个简单的两层感知机，用于识别手写数字图像：

第一层：神经元学习到边缘和线条等低级特征。

第二层：神经元组合这些低级特征，学习到数字的形状和结构。

通过这种方式，神经网络能够在不同层次上提取出越来越复杂的特征。可以实现更加复杂的任务

